{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emlo_input.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RxNQzudfQUB"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbqgjblIeY9x"
      },
      "source": [
        "max_word_length = 50 #최대 단어의 자수: 50자 \n",
        "_max_word_length = max_word_length # 50"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzETiIOjha8D"
      },
      "source": [
        "# char ids 0-255 come from utf-8 encoding bytes\n",
        "# assign 256-300 to special chars\n",
        "bos_char = 256  # <begin sentence>\n",
        "eos_char = 257  # <end sentence>\n",
        "\n",
        "bow_char = 258  # <begin word>\n",
        "eow_char = 259  # <end word>\n",
        "\n",
        "pad_char = 260 # <padding>"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz_YIR7dehms"
      },
      "source": [
        "num_words = 793471 #단어사전의 총 단어 개수"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiRHtGehfPg6",
        "outputId": "4a9bd2c4-9431-48a4-dd06-82310b3d30d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_word_char_ids = np.zeros([num_words, max_word_length], #793471, 50 \n",
        "  dtype=np.int32)\n",
        "_word_char_ids.shape # (100, 50) -> 100개 단어, 각 단어 자수: 최대 50자"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(793471, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ijV210WfSQV"
      },
      "source": [
        " # the charcter representation of the begin/end of sentence characters\n",
        "def _make_bos_eos(c):\n",
        "    r = np.zeros([max_word_length], dtype=np.int32) #최대 50문자\n",
        "    r[:] = pad_char \n",
        "    r[0] = bow_char # <begin word> -> 문자의 시작\n",
        "    r[1] = c\n",
        "    r[2] = eow_char # <end word> -> 문자의 끝\n",
        "    return r"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqPYeSU5fz5P",
        "outputId": "1f91934a-821a-46f1-86ce-ce40e47bb91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"bos_char:\", bos_char)\n",
        "bos_chars = _make_bos_eos(bos_char)\n",
        "print(\"bos_chars:\", bos_chars)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bos_char: 256\n",
            "bos_chars: [258 256 259 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260\n",
            " 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260\n",
            " 260 260 260 260 260 260 260 260 260 260 260 260 260 260]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv3bR_2Jf3Pn",
        "outputId": "20d580fd-f45a-49d6-ba1b-6329bf6faf99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"eos_char:\", eos_char)\n",
        "eos_chars = _make_bos_eos(eos_char)\n",
        "print(\"eos_chars:\", eos_chars)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eos_char: 257\n",
            "eos_chars: [258 257 259 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260\n",
            " 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260 260\n",
            " 260 260 260 260 260 260 260 260 260 260 260 260 260 260]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIhaMETBkGme"
      },
      "source": [
        "#import urllib\n",
        "import urllib.request"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wyr-x_KiVgM"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    '''\n",
        "    A token vocabulary.  Holds a map from token to ids and provides\n",
        "    a method for encoding text to a sequence of ids.\n",
        "    '''\n",
        "    def __init__(self, filename, validate_file=False):\n",
        "        '''\n",
        "        filename = the vocabulary file.  It is a flat text file with one\n",
        "            (normalized) token per line.  In addition, the file should also\n",
        "            contain the special tokens <S>, </S>, <UNK> (case sensitive).\n",
        "        '''\n",
        "        self._id_to_word = []\n",
        "        self._word_to_id = {}\n",
        "        self._unk = -1 #word_name == '<UNK>'\n",
        "        self._bos = -1 #word_name == '<S>'\n",
        "        self._eos = -1 #word_name == '</S>'\n",
        "\n",
        "        #with open(filename) as f:\n",
        "            #idx = 0\n",
        "            #for line in f:\n",
        "        \n",
        "        idx = 0\n",
        "        url = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/vocab-2016-09-10.txt\"\n",
        "        file = urllib.request.urlopen(url)\n",
        "        for line in file:\n",
        "          line = line.decode(\"utf-8\")\n",
        "          word_name = line.strip()\n",
        "          if word_name == '<S>':\n",
        "              self._bos = idx\n",
        "          elif word_name == '</S>':\n",
        "              self._eos = idx\n",
        "          elif word_name == '<UNK>':\n",
        "              self._unk = idx\n",
        "          if word_name == '!!!MAXTERMID':\n",
        "              continue\n",
        "\n",
        "          self._id_to_word.append(word_name)\n",
        "          self._word_to_id[word_name] = idx\n",
        "          idx += 1\n",
        "\n",
        "        # check to ensure file has special tokens\n",
        "        if validate_file:\n",
        "            if self._bos == -1 or self._eos == -1 or self._unk == -1:\n",
        "                raise ValueError(\"Ensure the vocabulary file has \"\n",
        "                                 \"<S>, </S>, <UNK> tokens\")\n",
        "\n",
        "    @property\n",
        "    def bos(self):\n",
        "        return self._bos\n",
        "\n",
        "    @property\n",
        "    def eos(self):\n",
        "        return self._eos\n",
        "\n",
        "    @property\n",
        "    def unk(self):\n",
        "        return self._unk\n",
        "\n",
        "    @property\n",
        "    def size(self):\n",
        "        return len(self._id_to_word)\n",
        "\n",
        "    def word_to_id(self, word):\n",
        "        if word in self._word_to_id:\n",
        "            return self._word_to_id[word]\n",
        "        return self.unk\n",
        "\n",
        "    def id_to_word(self, cur_id):\n",
        "        return self._id_to_word[cur_id]\n",
        "\n",
        "    def decode(self, cur_ids):\n",
        "        \"\"\"Convert a list of ids to a sentence, with space inserted.\"\"\"\n",
        "        return ' '.join([self.id_to_word(cur_id) for cur_id in cur_ids])\n",
        "\n",
        "    def encode(self, sentence, reverse=False, split=True):\n",
        "        \"\"\"Convert a sentence to a list of ids, with special tokens added.\n",
        "        Sentence is a single string with tokens separated by whitespace.\n",
        "        If reverse, then the sentence is assumed to be reversed, and\n",
        "            this method will swap the BOS/EOS tokens appropriately.\"\"\"\n",
        "\n",
        "        if split:\n",
        "            word_ids = [\n",
        "                self.word_to_id(cur_word) for cur_word in sentence.split()\n",
        "            ]\n",
        "        else:\n",
        "            word_ids = [self.word_to_id(cur_word) for cur_word in sentence]\n",
        "\n",
        "        if reverse:\n",
        "            return np.array([self.eos] + word_ids + [self.bos], dtype=np.int32)\n",
        "        else:\n",
        "            return np.array([self.bos] + word_ids + [self.eos], dtype=np.int32)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKvwWbmN73Sd",
        "outputId": "107f1bbd-0bdd-4eef-ca48-03ca4c9a3b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def test_urllib():\n",
        "  url = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/vocab-2016-09-10.txt\"\n",
        "  file = urllib.request.urlopen(url)\n",
        "  for line in file:\n",
        "    decoded_line = line.decode(\"utf-8\")\n",
        "    print(decoded_line)\n",
        "    break\n",
        "test_urllib()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "</S>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XwnX4T5jJrD"
      },
      "source": [
        "vocab_file = \"no_file\"\n",
        "vocab = Vocabulary(vocab_file, validate_file=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9etFtNjnQ7q",
        "outputId": "0ae1203e-5be3-402a-da0c-3826d6fd01ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(vocab._id_to_word)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-wCx7ymlEbb",
        "outputId": "8a6e2099-cd1a-42db-8709-9427886ed57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(vocab._id_to_word))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "793471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7NbYMNtlKxF",
        "outputId": "c112a331-d8a7-487e-965d-63b7f13f2208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(vocab._word_to_id.keys())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojxSd8QYlCYe",
        "outputId": "e7317158-0439-4617-f50e-152f9365d101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(vocab._unk)\n",
        "print(vocab._bos)\n",
        "print(vocab._eos)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-0wCHG5lyrz"
      },
      "source": [
        "def _convert_word_to_char_ids(word):\n",
        "    code = np.zeros([max_word_length], dtype=np.int32) #50\n",
        "    code[:] = pad_char\n",
        "\n",
        "    # utf-8로 인코딩된 word \n",
        "    word_encoded = word.encode('utf-8', 'ignore')[:(max_word_length-2)] #50-2=48\n",
        "    #print(\"word_encoded:\", word_encoded)\n",
        "    \n",
        "    code[0] = bow_char #begin of word -> 단어의 시작\n",
        "    # word의 한 문자씩 넣음\n",
        "    for k, chr_id in enumerate(word_encoded, start=1):\n",
        "        code[k] = chr_id\n",
        "    code[len(word_encoded) + 1] = eow_char #end of word -> 단어의 끝\n",
        "\n",
        "    return code"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaQ60GJwh56v"
      },
      "source": [
        "for i, word in enumerate(vocab._id_to_word):\n",
        "  #print(\"i:\", i)\n",
        "  #print(\"word:\", word)\n",
        "  _word_char_ids[i] = _convert_word_to_char_ids(word)\n",
        "  #print(\"_word_char_ids[i]:\", _word_char_ids[i])\n",
        "  #if i > 5:\n",
        "    #break"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV6KjuK_nGjm",
        "outputId": "93391857-46f0-4955-f749-220be69a8a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_word_char_ids.shape # (793471, 50)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(793471, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CwIW3xLno03",
        "outputId": "848e1432-8d56-498e-aef6-4a521452fc6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "_word_char_ids[0] # 한 단어씩 시작 "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([258,  60,  47,  83,  62, 259, 260, 260, 260, 260, 260, 260, 260,\n",
              "       260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260,\n",
              "       260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260,\n",
              "       260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezA80Bw_oast",
        "outputId": "41790aee-d759-4ace-9c9d-b060b035765e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 내부 접근을 외부 접근 가능 변수로 바꾸기 \n",
        "#@property\n",
        "#def bos(self):\n",
        "  #return self._bos\n",
        "vocab.bos"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch4vo6XEiAlD"
      },
      "source": [
        "# bos 단어에 대한 charids값\n",
        "# eos 단어에 대한 charids값\n",
        "_word_char_ids[vocab.bos] = bos_chars\n",
        "_word_char_ids[vocab.eos] = eos_chars"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnpwtQT27ipp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}